{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA on Speech Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import torchaudio.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = \"../src/Deep-Speech-2/data/audio/train-clean-100/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the sample audio file\n",
    "waveform, sample_rate = torchaudio.load(audio_path)\n",
    "\n",
    "print(f\"Sample Rate of {audio_path}: {sample_rate}\")\n",
    "\n",
    "# Plot the waveform\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(waveform.t().numpy())\n",
    "plt.show()\n",
    "\n",
    "# Play the audio\n",
    "display(Audio(audio_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the sample audio file\n",
    "log_mel_spec_transform = transforms.MelSpectrogram(\n",
    "    sample_rate=16000,\n",
    "    n_mels=128,\n",
    "    win_length=400,\n",
    "    hop_length=160,\n",
    "    n_fft = 1024\n",
    ")\n",
    "\n",
    "# Compute the log-mel spectrogram\n",
    "log_mel_spec = log_mel_spec_transform(waveform)\n",
    "log_mel_spec = torch.log(log_mel_spec + 1e-14)  # Avoid log(0)\n",
    "\n",
    "# Display the original spectrogram\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.imshow(log_mel_spec.squeeze(0).numpy(), cmap='viridis', origin='lower', aspect='auto')\n",
    "plt.title(\"Original Log-Mel Spectrogram\")\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal SpecAugment transformations\n",
    "spec_augment = nn.Sequential(\n",
    "                transforms.FrequencyMasking(freq_mask_param=30),\n",
    "                transforms.TimeMasking(time_mask_param=70)\n",
    ")\n",
    "\n",
    "# Applying SpecAugment\n",
    "augmented_log_mel_spec = spec_augment(log_mel_spec)\n",
    "\n",
    "# Display augmented spectrogram\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.imshow(augmented_log_mel_spec.squeeze(0).numpy(), cmap='viridis', origin='lower', aspect='auto')\n",
    "plt.title(\"Augmented Log-Mel Spectrogram\")\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heavy SpecAugment transformations\n",
    "time_masks = [torchaudio.transforms.TimeMasking(time_mask_param=15, p=0.05) for _ in range(10)]\n",
    "\n",
    "spec_augment = nn.Sequential(\n",
    "                transforms.FrequencyMasking(freq_mask_param=25),\n",
    "                *time_masks\n",
    "            )\n",
    "\n",
    "# Applying SpecAugment\n",
    "augmented_log_mel_spec = spec_augment(log_mel_spec)\n",
    "\n",
    "# Display augmented spectrogram\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.imshow(augmented_log_mel_spec.squeeze(0).numpy(), cmap='viridis', origin='lower', aspect='auto')\n",
    "plt.title(\"Augmented Log-Mel Spectrogram\")\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
